# Why Variable selection is important?

**Feature selection** is a technique for **`reducing`** the number of features and thus the **`computational complexity`** of the model. We want to explain the data as simply as 
possible, so **redundant** predictors should be removed.Unnecessary predictors will introduce **`noise`** into the estimation of other quantities of interest. **Collinearity** 
occurs when too many variables attempt to perform the same function. We can save time and/or money by not measuring redundant predictors if the model is to be used 
for prediction.The goal of feature selection is to build a model that **`accurately`** predicts or explains the relationships in the data.

# Methods to determine variables for regression.

The selection of variables is an **important** part of regression because a model with a large number of variables can lead to computational complexity. There are
several methods for determining the variable that will help our regression model predict accurately. Depending on the `number of variables`, `type of data`, and 
`EDA analysis`, I intend to use the following methods for variable selection.
